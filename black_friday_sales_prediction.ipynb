{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba0961b-b813-43d2-aaa5-801f2f7c6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8e367-7504-4380-b896-8f678f2d1b5a",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a51067-b917-4c77-950f-bd2f85133c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_Vges7qu.csv')\n",
    "sample_submission = pd.read_csv('sample_submission_V9Inaty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3ef92e-7354-4a6e-ad0d-1429e67ed9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Head:\n",
      "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
      "0  1000001  P00069042      F  0-17          10             A   \n",
      "1  1000001  P00248942      F  0-17          10             A   \n",
      "2  1000001  P00087842      F  0-17          10             A   \n",
      "3  1000001  P00085442      F  0-17          10             A   \n",
      "4  1000002  P00285442      M   55+          16             C   \n",
      "\n",
      "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
      "0                          2               0                   3   \n",
      "1                          2               0                   1   \n",
      "2                          2               0                  12   \n",
      "3                          2               0                  12   \n",
      "4                         4+               0                   8   \n",
      "\n",
      "   Product_Category_2  Product_Category_3  Purchase  \n",
      "0                 NaN                 NaN      8370  \n",
      "1                 6.0                14.0     15200  \n",
      "2                 NaN                 NaN      1422  \n",
      "3                14.0                 NaN      1057  \n",
      "4                 NaN                 NaN      7969  \n",
      "\n",
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   User_ID                     550068 non-null  int64  \n",
      " 1   Product_ID                  550068 non-null  object \n",
      " 2   Gender                      550068 non-null  object \n",
      " 3   Age                         550068 non-null  object \n",
      " 4   Occupation                  550068 non-null  int64  \n",
      " 5   City_Category               550068 non-null  object \n",
      " 6   Stay_In_Current_City_Years  550068 non-null  object \n",
      " 7   Marital_Status              550068 non-null  int64  \n",
      " 8   Product_Category_1          550068 non-null  int64  \n",
      " 9   Product_Category_2          376430 non-null  float64\n",
      " 10  Product_Category_3          166821 non-null  float64\n",
      " 11  Purchase                    550068 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 50.4+ MB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 233599 entries, 0 to 233598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Comb                        233599 non-null  object \n",
      " 1   User_ID                     233599 non-null  int64  \n",
      " 2   Product_ID                  233599 non-null  object \n",
      " 3   Gender                      233599 non-null  object \n",
      " 4   Age                         233599 non-null  object \n",
      " 5   Occupation                  233599 non-null  int64  \n",
      " 6   City_Category               233599 non-null  object \n",
      " 7   Stay_In_Current_City_Years  233599 non-null  object \n",
      " 8   Marital_Status              233599 non-null  int64  \n",
      " 9   Product_Category_1          233599 non-null  int64  \n",
      " 10  Product_Category_2          161255 non-null  float64\n",
      " 11  Product_Category_3          71037 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(6)\n",
      "memory usage: 21.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Display the information about the training data, including data types and missing values\n",
    "print(\"\\nTraining Data Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "# Display the information about the test data\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f84465-21c4-433f-9ee5-62b03a83d8ad",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2da3bb4-6980-46ad-a4b7-10c18caf1a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\AppData\\Local\\Temp\\ipykernel_101696\\633073254.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Product_Category_2'].fillna(0, inplace=True)\n",
      "C:\\Users\\arjun\\AppData\\Local\\Temp\\ipykernel_101696\\633073254.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Product_Category_3'].fillna(0, inplace=True)\n",
      "C:\\Users\\arjun\\AppData\\Local\\Temp\\ipykernel_101696\\633073254.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_processed['Purchase'] = train_purchase\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test data for consistent preprocessing\n",
    "train_purchase = train_df['Purchase']\n",
    "train_df.drop('Purchase', axis=1, inplace=True)\n",
    "\n",
    "# Align columns before concatenation\n",
    "test_df.drop('Comb', axis=1, inplace=True)\n",
    "\n",
    "# Concatenate for preprocessing\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True, sort=False)\n",
    "\n",
    "# Handle the 'Stay_In_Current_City_Years' column\n",
    "# Replace '4+' with 4 and convert to integer type\n",
    "combined_df['Stay_In_Current_City_Years'] = combined_df['Stay_In_Current_City_Years'].str.replace('+', '').astype(int)\n",
    "\n",
    "# Fill missing values in Product_Category_2 and Product_Category_3 with a placeholder (e.g., 0)\n",
    "# This is a common practice when missing values represent the absence of a feature\n",
    "combined_df['Product_Category_2'].fillna(0, inplace=True)\n",
    "combined_df['Product_Category_3'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert `Product_ID` and `User_ID` to categorical type for LightGBM\n",
    "# This is an efficient way to handle high-cardinality categorical features\n",
    "categorical_features = ['Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years', 'Occupation', 'Marital_Status', 'Product_ID', 'User_ID']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    combined_df[feature] = combined_df[feature].astype('category')\n",
    "    \n",
    "# Separate the combined data back into training and test sets\n",
    "train_processed = combined_df[:len(train_df)]\n",
    "test_processed = combined_df[len(train_df):]\n",
    "\n",
    "# Add the 'Purchase' column back to the training data\n",
    "train_processed['Purchase'] = train_purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35e53a-1869-49ea-8e23-c59a8b29d676",
   "metadata": {},
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81dd3679-29bb-4dc3-b95b-994a768616fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\arjun\\anaconda3\\lib\\site-packages (4.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\arjun\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\arjun\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca77c00-a1d1-4cdd-a958-17ac8bdb7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66261ef8-92b6-4009-a26a-76581266cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = train_processed.drop(['Purchase'], axis=1)\n",
    "y = train_processed['Purchase']\n",
    "\n",
    "# Define categorical features for LightGBM\n",
    "cat_features = [col for col in X.columns if X[col].dtype.name == 'category']\n",
    "\n",
    "# Initialize the LightGBM Regressor model\n",
    "params = {\n",
    "    'objective': 'regression_l1', # MAE objective, good for robustness to outliers\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "model.fit(X, y, categorical_feature=cat_features)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c208-2d21-40ee-9cae-e88abae03e7c",
   "metadata": {},
   "source": [
    "### Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "186db10e-7825-43ed-b1b8-53fe29f065ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission.csv' created successfully.\n",
      "\n",
      "Sample of the submission file:\n",
      "        User_ID Product_ID      Purchase\n",
      "550068  1000004  P00128942  16349.017264\n",
      "550069  1000009  P00113442  11526.149683\n",
      "550070  1000010  P00288442   6105.360659\n",
      "550071  1000010  P00145342   4133.195845\n",
      "550072  1000011  P00053842   2609.572352\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the preprocessed test data\n",
    "test_predictions = model.predict(test_processed)\n",
    "\n",
    "# Ensure predictions are positive since purchase amounts cannot be negative\n",
    "test_predictions[test_predictions < 0] = 0\n",
    "\n",
    "# Create the submission DataFrame in the required format\n",
    "submission_df = pd.DataFrame({\n",
    "    'User_ID': test_processed['User_ID'].astype(int),\n",
    "    'Product_ID': test_processed['Product_ID'].astype(str),\n",
    "    'Purchase': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file to a CSV\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nSubmission file 'submission.csv' created successfully.\")\n",
    "print(\"\\nSample of the submission file:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efeae67-8843-42a9-a363-d61e9ebfe977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
